# Policy-as-Code-Engine-for-Academic-Compliance 
*A Local RAG System for Clause-Level Regulatory Interpretation*

---

## ğŸ“Œ Overview

This project builds a **local Retrieval-Augmented Generation (RAG)**â€“based engine to help academic institutions interpret regulations from **UGC**, **AICTE**, and internal policy documents.  
Admins can ask **natural-language questions**, and the system returns:

- **Grounded answers** based strictly on retrieved clauses  
- **Citations** indicating the exact policy source  
- **Top-k retrieved text segments** with similarity distances  
- **Precedence-aware reasoning** using a Policy-as-Code layer  

The entire system is designed to run **offline**, ensuring privacy, security, and reliability.

---

## ğŸ¯ Problem Statement

Academic regulations are scattered across multiple authorities and formats (PDFs, scans, circulars). Institutions struggle to:

- Locate relevant clauses quickly  
- Interpret conflicting guidelines  
- Provide citation-backed decisions  
- Maintain consistent compliance  

This project solves these gaps by creating a **centralized, searchable, clause-level compliance engine**.

---

## ğŸ—ï¸ System Architecture

### **1. Offline Ingestion Pipeline**
- PDF collection from UGC, AICTE, institutional sources  
- OCR for scanned PDFs  
- Text cleaning (header/footer removal, noise filtering)  
- Clause segmentation into small sections  
- Metadata tagging:
  - issuing body  
  - year  
  - category (admissions, exams, PhD, anti-ragging, etc.)  
- Embedding using **`nomic-embed-text`**  
- Stored in **ChromaDB** (`policy_docs` collection)

### **2. Online Query Engine**
User question â†’ embedding â†’ top-k retrieval â†’ prompt construction â†’ LLM answer (Qwen 2.5 3B Instruct)


Ensures **trustworthy, deterministic compliance reasoning**.

---

## ğŸ’¡ Features

-  **Semantic clause-level search**  
- **RAG with local LLM (Qwen 2.5 3B via Ollama)**  
- **Multi-source knowledge base (PDFs â†’ OCR â†’ embeddings)**  
- **Citations and source distances**  
- **Fully local, offline system**  
- **Anti-hallucination prompting**  
- **Clean ingestion pipeline for policy documents**

---

## ğŸ–¥ï¸ Tech Stack

| Component | Tool/Model |
|----------|------------|
| LLM | Qwen 2.5 3B Instruct (Ollama) |
| Embeddings | nomic-embed-text |
| Vector Store | ChromaDB |
| OCR |  pytesseract |
| Backend Notebooks | Python, Jupyter |
| Storage | Local |

---

## ğŸ“‚ Repository Structure
```
Policy-as-Code-Engine-for-Academic-Compliance/
â”‚
â”œâ”€â”€ Chroma_db_database/
â”‚
â”œâ”€â”€ Data/
â”‚    â”œâ”€â”€ CleanedText/
|    â”œâ”€â”€ Review/
|
â”œâ”€â”€ Diagrams/
â”‚
â”œâ”€â”€ Major Research Paper Analysis (Abhinav)/
â”‚
â”œâ”€â”€ Notebooks/
â”‚   â”œâ”€â”€ Data Ingestion/
â”‚   â”‚   â”œâ”€â”€ Notebooks of Data ingestion
â”‚   â”œâ”€â”€ Experimental_Testing/
â”‚   â”‚   â”œâ”€â”€ experiment_results/
â”‚   â”‚   â”œâ”€â”€ Comparison_7b_vs_3b notebook/
â”‚   â”‚   â”œâ”€â”€ Prompt Engineering notebook/
â”‚   â”‚   â””â”€â”€ Top-k notebok/
â”‚   â”œâ”€â”€ LLM_Integration notebook/
|
â”‚â”€â”€ RAG_Virtual_env/
â”‚
â”œâ”€â”€ Testing_notebooks/
â”‚
â”œâ”€â”€ Video_Demonstration/
â”‚
â”œâ”€â”€ Workflow
â”‚
â”œâ”€â”€ requirements.txt
|
â”œâ”€â”€ README.md
|
â””â”€â”€ .gitignore

```

---

## ğŸš€ Running the System

### **Prerequisites**
- Python 3.13.4
- Ollama installed  
- Qwen model pulled:
  ```
  ollama pull qwen2.5:3b-instruct
  ```
Install Dependencies
```
pip install requirements.txt
```


## Experiments & Results
* Experiment 1 â€“ Model Comparison
Compared Qwen 2.5 3B vs 7B â†’
**Qwen 3B** performed better in accuracy, speed, and efficiency.

* Experiment 2 â€“ Top-K Retrieval
Top-k values tested: 1, 3, 5
â†’ **k = 3** gave best quality/noise balance.

* Experiment 3 â€“ Prompt Engineering
Evaluated 8 prompt types
â†’ **Chain of thought** Prompt achieved optimal results.


## Future Enhancements
* Web UI

* Fine-grained clause classification using LLMs

* Improved evaluation framework

* GPU-optimized local inference

